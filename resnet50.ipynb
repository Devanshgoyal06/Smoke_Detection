{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ea74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb4ff10",
   "metadata": {},
   "source": [
    "## Preprocessing test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33597535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 912 images belonging to 2 classes.\n",
      "Found 227 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 5,\n",
    "                                   shear_range = 0.2,\n",
    "                                   validation_split=0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(r\"C:\\Users\\DEVANSH\\OneDrive\\Desktop\\smoke train\",\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 subset=\"training\",\n",
    "                                                 batch_size = 20,\n",
    "                                                 class_mode = 'binary')\n",
    "validation_set = train_datagen.flow_from_directory(r\"C:\\Users\\DEVANSH\\OneDrive\\Desktop\\smoke train\",\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 subset=\"validation\",\n",
    "                                                 batch_size = 20,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d26783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"no smoke\",\"smoke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88d24f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 267 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(r\"C:\\Users\\DEVANSH\\OneDrive\\Desktop\\smoke test\",\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 20,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722a33d",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b21215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [keras.layers.Conv2D(filters, 3, strides=strides,padding=\"same\", use_bias=False),\n",
    "                            keras.layers.BatchNormalization(),\n",
    "                            self.activation,keras.layers.Conv2D(filters, 3, strides=1,padding=\"same\", use_bias=False), \n",
    "                            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [keras.layers.Conv2D(filters, 1, strides=strides,padding=\"same\", use_bias=False),\n",
    "                                keras.layers.BatchNormalization()]\n",
    "def call(self, inputs):\n",
    "    Z = inputs\n",
    "    for layer in self.main_layers:\n",
    "        Z = layer(Z)\n",
    "    skip_Z = inputs\n",
    "    for layer in self.skip_layers:\n",
    "        skip_Z = layer(skip_Z)\n",
    "    return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de314464",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=[224, 224, 3],padding=\"same\", use_bias=False))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(\"relu\"))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n",
    "prev_filters = 64\n",
    "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    model.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "model.add(keras.layers.GlobalAvgPool2D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129bca4",
   "metadata": {},
   "source": [
    "## Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bfd6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0523328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914a8d5",
   "metadata": {},
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "802795f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "46/46 [==============================] - 45s 940ms/step - loss: 0.4603 - accuracy: 0.8059 - val_loss: 0.6134 - val_accuracy: 0.8062\n",
      "Epoch 2/40\n",
      "46/46 [==============================] - 38s 830ms/step - loss: 0.4053 - accuracy: 0.8059 - val_loss: 0.5959 - val_accuracy: 0.8062\n",
      "Epoch 3/40\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.3850 - accuracy: 0.8059 - val_loss: 0.5524 - val_accuracy: 0.8062\n",
      "Epoch 4/40\n",
      "46/46 [==============================] - 38s 832ms/step - loss: 0.3794 - accuracy: 0.8059 - val_loss: 0.5149 - val_accuracy: 0.8062\n",
      "Epoch 5/40\n",
      "46/46 [==============================] - 37s 813ms/step - loss: 0.3734 - accuracy: 0.8059 - val_loss: 0.4934 - val_accuracy: 0.8062\n",
      "Epoch 6/40\n",
      "46/46 [==============================] - 37s 800ms/step - loss: 0.3581 - accuracy: 0.8059 - val_loss: 0.4445 - val_accuracy: 0.8062\n",
      "Epoch 7/40\n",
      "46/46 [==============================] - 37s 803ms/step - loss: 0.3635 - accuracy: 0.8059 - val_loss: 0.4354 - val_accuracy: 0.8062\n",
      "Epoch 8/40\n",
      "46/46 [==============================] - 37s 798ms/step - loss: 0.3595 - accuracy: 0.8059 - val_loss: 0.4189 - val_accuracy: 0.8062\n",
      "Epoch 9/40\n",
      "46/46 [==============================] - 37s 812ms/step - loss: 0.3576 - accuracy: 0.8059 - val_loss: 0.4021 - val_accuracy: 0.8062\n",
      "Epoch 10/40\n",
      "46/46 [==============================] - 37s 803ms/step - loss: 0.3534 - accuracy: 0.8059 - val_loss: 0.3956 - val_accuracy: 0.8062\n",
      "Epoch 11/40\n",
      "46/46 [==============================] - 37s 797ms/step - loss: 0.3458 - accuracy: 0.8059 - val_loss: 0.3863 - val_accuracy: 0.8062\n",
      "Epoch 12/40\n",
      "46/46 [==============================] - 37s 804ms/step - loss: 0.3471 - accuracy: 0.8059 - val_loss: 0.3620 - val_accuracy: 0.8062\n",
      "Epoch 13/40\n",
      "46/46 [==============================] - 37s 798ms/step - loss: 0.3509 - accuracy: 0.8059 - val_loss: 0.3722 - val_accuracy: 0.8062\n",
      "Epoch 14/40\n",
      "46/46 [==============================] - 37s 799ms/step - loss: 0.3452 - accuracy: 0.8059 - val_loss: 0.3642 - val_accuracy: 0.8062\n",
      "Epoch 15/40\n",
      "46/46 [==============================] - 37s 800ms/step - loss: 0.3391 - accuracy: 0.8059 - val_loss: 0.3911 - val_accuracy: 0.8062\n",
      "Epoch 16/40\n",
      "46/46 [==============================] - 37s 798ms/step - loss: 0.3344 - accuracy: 0.8059 - val_loss: 0.3870 - val_accuracy: 0.8062\n",
      "Epoch 17/40\n",
      "46/46 [==============================] - 37s 798ms/step - loss: 0.3372 - accuracy: 0.8059 - val_loss: 0.3699 - val_accuracy: 0.8062\n",
      "Epoch 18/40\n",
      "46/46 [==============================] - 37s 805ms/step - loss: 0.3410 - accuracy: 0.8059 - val_loss: 0.3765 - val_accuracy: 0.8062\n",
      "Epoch 19/40\n",
      "46/46 [==============================] - 37s 803ms/step - loss: 0.3331 - accuracy: 0.8059 - val_loss: 0.3623 - val_accuracy: 0.8062\n",
      "Epoch 20/40\n",
      "46/46 [==============================] - 37s 799ms/step - loss: 0.3376 - accuracy: 0.8059 - val_loss: 0.4331 - val_accuracy: 0.8062\n",
      "Epoch 21/40\n",
      "46/46 [==============================] - 37s 801ms/step - loss: 0.3358 - accuracy: 0.8059 - val_loss: 0.4176 - val_accuracy: 0.8062\n",
      "Epoch 22/40\n",
      "46/46 [==============================] - 37s 807ms/step - loss: 0.3296 - accuracy: 0.8059 - val_loss: 0.4153 - val_accuracy: 0.8062\n",
      "Epoch 23/40\n",
      "46/46 [==============================] - 37s 800ms/step - loss: 0.3290 - accuracy: 0.8059 - val_loss: 0.5142 - val_accuracy: 0.8062\n",
      "Epoch 24/40\n",
      "46/46 [==============================] - 37s 802ms/step - loss: 0.3310 - accuracy: 0.8059 - val_loss: 0.5124 - val_accuracy: 0.8062\n",
      "Epoch 25/40\n",
      "46/46 [==============================] - 37s 813ms/step - loss: 0.3342 - accuracy: 0.8059 - val_loss: 0.3897 - val_accuracy: 0.8062\n",
      "Epoch 26/40\n",
      "46/46 [==============================] - 37s 798ms/step - loss: 0.3246 - accuracy: 0.8059 - val_loss: 0.4668 - val_accuracy: 0.8062\n",
      "Epoch 27/40\n",
      "46/46 [==============================] - 37s 802ms/step - loss: 0.3311 - accuracy: 0.8059 - val_loss: 0.4525 - val_accuracy: 0.8062\n",
      "Epoch 28/40\n",
      "46/46 [==============================] - 37s 807ms/step - loss: 0.3226 - accuracy: 0.8059 - val_loss: 0.3526 - val_accuracy: 0.8062\n",
      "Epoch 29/40\n",
      "46/46 [==============================] - 37s 803ms/step - loss: 0.3287 - accuracy: 0.8059 - val_loss: 0.3437 - val_accuracy: 0.8062\n",
      "Epoch 30/40\n",
      "46/46 [==============================] - 37s 809ms/step - loss: 0.3333 - accuracy: 0.8059 - val_loss: 0.3471 - val_accuracy: 0.8062\n",
      "Epoch 31/40\n",
      "46/46 [==============================] - 37s 805ms/step - loss: 0.3345 - accuracy: 0.8059 - val_loss: 0.3562 - val_accuracy: 0.8062\n",
      "Epoch 32/40\n",
      "46/46 [==============================] - 37s 796ms/step - loss: 0.3255 - accuracy: 0.8059 - val_loss: 0.6003 - val_accuracy: 0.8062\n",
      "Epoch 33/40\n",
      "46/46 [==============================] - 37s 795ms/step - loss: 0.3239 - accuracy: 0.8059 - val_loss: 0.4779 - val_accuracy: 0.8062\n",
      "Epoch 34/40\n",
      "46/46 [==============================] - 37s 803ms/step - loss: 0.3200 - accuracy: 0.8059 - val_loss: 0.3538 - val_accuracy: 0.8062\n",
      "Epoch 35/40\n",
      "46/46 [==============================] - 37s 803ms/step - loss: 0.3259 - accuracy: 0.8059 - val_loss: 0.3704 - val_accuracy: 0.8062\n",
      "Epoch 36/40\n",
      "46/46 [==============================] - 37s 810ms/step - loss: 0.3119 - accuracy: 0.8059 - val_loss: 0.3806 - val_accuracy: 0.8062\n",
      "Epoch 37/40\n",
      "46/46 [==============================] - 37s 811ms/step - loss: 0.3158 - accuracy: 0.8059 - val_loss: 0.4743 - val_accuracy: 0.8062\n",
      "Epoch 38/40\n",
      "46/46 [==============================] - 38s 820ms/step - loss: 0.3156 - accuracy: 0.8059 - val_loss: 0.3732 - val_accuracy: 0.8062\n",
      "Epoch 39/40\n",
      "46/46 [==============================] - 40s 859ms/step - loss: 0.3286 - accuracy: 0.8059 - val_loss: 0.3957 - val_accuracy: 0.8062\n",
      "Epoch 40/40\n",
      "46/46 [==============================] - 38s 821ms/step - loss: 0.3293 - accuracy: 0.8059 - val_loss: 0.3426 - val_accuracy: 0.8062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2790ee68400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_set, epochs = 40, validation_data = validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea103704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
